<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Multinomial Classification</title>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.6.0/build/styles/github.min.css">
<script src="https://cdn.jsdelivr.net/combine/gh/highlightjs/cdn-release@11.6.0/build/highlight.min.js,npm/@xiee/utils/js/load-highlight.js" async></script>



<style type="text/css">
body, td {
  font-family: sans-serif;
  background-color: white;
  font-size: 13px;
}
body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 1.5;
}
tt, code, pre {
  font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}
a:visited { color: #80007f; }
pre, img { max-width: 100%; }
code {
  font-size: 92%;
  border: 1px solid #ccc;
}
code[class] { background-color: #F8F8F8; }
code.language-undefined { background-color: inherit; }
table {
  margin: auto;
  border-top: 1px solid #666;
  border-bottom: 1px solid #666;
}
table thead th { border-bottom: 1px solid #ddd; }
th, td { padding: 5px; }
thead, tfoot, tr:nth-child(even) { background: #eee; }
blockquote {
  color:#666;
  margin:0;
  padding-left: 1em;
  border-left: 0.5em #eee solid;
}
hr { border: 1px #ddd dashed; }

@media print {
  * {
    background: transparent !important;
    color: black !important;
    filter:none !important;
  }
  body {
    font-size: 12pt;
    max-width: 100%;
  }
  a, a:visited { text-decoration: underline; }
  hr {
    visibility: hidden;
    page-break-before: always;
  }
  pre, blockquote {
    padding-right: 1em;
    page-break-inside: avoid;
  }
  tr, img { page-break-inside: avoid; }
  img { max-width: 100% !important; }
  @page :left { margin: 15mm 20mm 15mm 10mm; }
  @page :right { margin: 15mm 10mm 15mm 20mm; }
  p, h2, h3 { orphans: 3; widows: 3; }
  h2, h3 { page-break-after: avoid; }
}
</style>



</head>

<body>
<pre><code class="language-r">library(tidyverse) # Data wrangling
library(tidyfit)   # Auto-ML modeling
</code></pre>
<p>Multinomial classification is possible in <code>tidyfit</code> using the methods powered by <code>glmnet</code>, <code>e1071</code> and <code>randomForest</code> (LASSO, Ridge, ElasticNet,  AdaLASSO, SVM and Random Forest). Currently, none of the other methods support multinomial classification.^[Feature selection methods such as <code>relief</code> or <code>chisq</code> can be used with multinomial response variables. I may also add support for multinomial classification with <code>mboost</code> in future.] When the response variable contains more than 2 classes, <code>classify</code> automatically uses a multinomial response for the above-mentioned methods.</p>
<p>Here’s an example using the built-in <code>iris</code> dataset:</p>
<pre><code class="language-r">data(&quot;iris&quot;)

# For reproducibility
set.seed(42)
ix_tst &lt;- sample(1:nrow(iris), round(nrow(iris)*0.2))

data_trn &lt;- iris[-ix_tst,]
data_tst &lt;- iris[ix_tst,]

as_tibble(iris)
#&gt; # A tibble: 150 × 5
#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
#&gt;           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  
#&gt;  1          5.1         3.5          1.4         0.2 setosa 
#&gt;  2          4.9         3            1.4         0.2 setosa 
#&gt;  3          4.7         3.2          1.3         0.2 setosa 
#&gt;  4          4.6         3.1          1.5         0.2 setosa 
#&gt;  5          5           3.6          1.4         0.2 setosa 
#&gt;  6          5.4         3.9          1.7         0.4 setosa 
#&gt;  7          4.6         3.4          1.4         0.3 setosa 
#&gt;  8          5           3.4          1.5         0.2 setosa 
#&gt;  9          4.4         2.9          1.4         0.2 setosa 
#&gt; 10          4.9         3.1          1.5         0.1 setosa 
#&gt; # … with 140 more rows
</code></pre>
<h2>Penalized classification algorithms to predict <code>Species</code></h2>
<p>The code chunk below fits the above mentioned algorithms on the training split, using a 10-fold cross validation to select optimal penalties. We then obtain out-of-sample predictions using <code>predict</code>. Unlike binomial classification, the <code>fit</code> and <code>pred</code> objects contain a <code>class</code> column with separate coefficients and predictions for each class. The predictions sum to one across classes:</p>
<pre><code class="language-r">fit &lt;- data_trn %&gt;% 
  classify(Species ~ ., 
           LASSO = m(&quot;lasso&quot;), 
           Ridge = m(&quot;ridge&quot;), 
           ElasticNet = m(&quot;enet&quot;), 
           AdaLASSO = m(&quot;adalasso&quot;),
           SVM = m(&quot;svm&quot;),
           `Random Forest` = m(&quot;rf&quot;),
           `Least Squares` = m(&quot;ridge&quot;, lambda = 1e-5), 
           .cv = &quot;vfold_cv&quot;)

pred &lt;- fit %&gt;% 
  predict(data_tst)
</code></pre>
<p>Note that we can add unregularized least squares estimates by setting <code>lambda = 0</code> (or very close to zero).</p>
<p>Next, we can use <code>yardstick</code> to calculate the log loss accuracy metric and compare the performance of the different models:</p>
<pre><code class="language-r">metrics &lt;- pred %&gt;% 
  group_by(model, class) %&gt;% 
  mutate(row_n = row_number()) %&gt;% 
  spread(class, prediction) %&gt;% 
  group_by(model) %&gt;% 
  yardstick::mn_log_loss(truth, setosa:virginica)

metrics %&gt;% 
  mutate(model = str_wrap(model, 11)) %&gt;% 
  ggplot(aes(model, .estimate)) +
  geom_col(fill = &quot;darkblue&quot;) +
  theme_bw() +
  theme(axis.title.x = element_blank())
</code></pre>
<img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-5" style="display: block; margin: auto;" />
<p>The least squares estimate performs poorest, while the random forest (nonlinear) and the support vector machine (SVM) achieve the best results. The SVM is estimated with a linear kernel by default (use <code>kernel = &lt;chosen_kernel&gt;</code> to use a different kernel).</p>


<script src="https://cdn.jsdelivr.net/combine/npm/@xiee/utils/js/center-img.min.js" async></script>
</body>

</html>
